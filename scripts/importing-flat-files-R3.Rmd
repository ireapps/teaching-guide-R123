---
title: "Importing with readr"
author: "Liz Lucas, IRE"
output: 
---

First things first: getting your data into R. For a lot of other programs (ahem SQL) this can be a very painful process, but R, and the tidyverse specifically, makes importing a dream. You figure out exactly how to do it and then you can rerun the import script as many times as you need.

Importing into R doesn't change the data file, it reads the data from the file into your environment. R will either read your data into the console, or into a variable to be stored in your environment.

Always add your packages at the top of your script:

1.  `readr`, part of tidyverse, to import flat text files;
2.  `readxl` to import excel files;
3.  `googlesheets4` to import data from a google sheet;
4.  `RSocrata` to import data in a Socrata API;
5.  `janitor` package to clean things up a bit.

```{r setup}
library(readr) #you can also use library(tidyverse) to bring in all the packages
library(readxl)
library(googlesheets4)
library(RSocrata)
library(janitor)
```

### CSVs

Before you import data, explore the options associated with `read_csv()` by looking at the docs. Note that you can pop open the documents as a separate window.

```{r}
?read_csv
```

Note that there are a group of functions that show up, including read_tsv and read_delim. These are functions you can use for files with different formatting: tsv imports a tab-delimited file, and read_delim allows you to specify another delimiter.

You can also include optional arguments to:

-   specify column names (if your file doesn't have them) `col_names = c("name1", "name2", "name3")`
-   specify data types for each column `col_types = "nnnnnccccc"` (five numeric columns followed by five character columns)
-   import everything as character `col_types = cols(.default = "c")`
-   skip rows if your file has extra header rows `skip = 2`

To illustrate some of these options, we'll use a file from the Columbia, MO city website on vendor payments called "ledger.csv". Take a look at the file in Sublime Text and think through what arguments you may need above. 

```{r}

```

Note that this file has a header row, although some of the names aren't very tidy (two have a space, and one has an odd character, a `#`. R will allow these to be column names but you need to put them between backticks (\`) for R to recognize them as such).

If we use the `col_names` argument to say that this file does not have a header row, it will regard the first row as a row of data:

```{r}
ledger <- read_csv("data/ledger.csv", col_names=FALSE)
```

If we use `col_names` to specify a new set of column names, it will also assume the file does not have a header row:

```{r}
ledger <- read_csv("data/ledger.csv", col_names=c("col1", "col2", "col3", "col4", "col5", "col6"))
```

Let's talk data types. There's one column in here I might want to change: the Check \# column. It's not a true number (I wouldn't want to do math on it) so I might want to import it as a character field. Use `col_types` to specify one character type for each column. See the documentation for the different data types:

-   c = character
-   i = integer
-   n = number
-   d = double
-   l = logical
-   f = factor
-   D = date
-   T = date time
-   t = time
-   ? = guess
-   \_ or - = skip

For this file, I want four character columns, one date time column and one number column, in that order:

```{r}
ledger <- read_csv("data/ledger.csv", col_types="ccccTn")
```

Alternately, I could import everthing as character. Sometimes this is the easiest way to import really dirty data, and then you can clean things up and convert columns to dates and numbers as you see fit:

```{r}
ledger <- read_csv("data/ledger.csv", col_types = cols(.default = "c"))
```

To change just one column type, enter `?` for the rest of the columns (this tells R to guess, which it's good at):

```{r}
ledger <- read_csv("data/ledger.csv", col_types = "???c??")
```

Or use `cols` if you don't want to type a bunch of question marks:

```{r}
ledger <- read_csv("data/ledger.csv", col_types = cols(`Check #` = "c"))
```

Note that the column names in this file are a mess. They are titlecase with spaces and weird characters. To clean up the names (make lowercase, replace spaces and weird characters with _), use `clean_names()` from the `janitor` package:

```{r}
ledger <- clean_names(ledger)
```

ðŸ‘‰ YOUR TURN
Take a look at the file `transactions.csv` in your data folder; open it up in Sublime Text and think about what arguments you might use. Write an import script below bringing the data into a variable called `transactions`:  
```{r}

```


### Importing other types of flat files

Sometimes you're data isn't a CSV. If it's tab delimited, for example, use `read_tsv()`. If it's delimited by something other than a comma or a tab, use `read_delim()` and specify the delimiter. 

Examples: mlb_tab.tsv and mlb_semicolon.txt
```{r}
mlb <- read_tsv("data/mlb_tab.tsv")

mlb <- read_delim("data/mlb_semicolon.txt", delim=';')

?read_delim
```


### Importing excel files

This is relatively straightforward, and primarily we use the function `read_excel()` to import .xlsx or .xls files. This function has very similar arguments to `read_csv()`, and you can use the col_names and col_types arguments in the same way. With `read_excel()`, you can also specify what sheet in an excel workbook you want to import. In our example, `salaries.xlsx`, the first sheet is the data and the second is a notes tab, so we'll just import the first:

```{r}

```

Note that you can import many different types of files to R, using several different packages. These are just the most commonly used by journalists. You just have to find the right function and the right package for what you need. Check out the `foreign` package, for example, which is great at helping you import large survey files of various types.

### Importing from Google Sheets

This requires that you sign into your Google account, so don't run this code if you don't want to sign in on the lab computers (and you probably don't). Try running it at home; you can substitute this URL with a URL from your own Google Sheets data. 

```{r}
mlb <- read_sheet("https://docs.google.com/spreadsheets/d/1L1xtYvFm3B3gfAM1QjpkHd7NSsMAxoJgpYPgH-I6tL8/edit#gid=1558932597")
```

### Importing from RSocrata

Lots of open data portals maintained by government agencies are built using Socrata. The database pages are all structured the same, and there are API endpoints for these datasets. Accessing them this way is sometimes more convenient than downloading the data if, for example, you don't to store a large data file on your computer or you want to constantly be working with updated data. Socrata has a 1000 row limit for regular requests, but the RSocrata package bypasses that limit for you. Just grap the API Endpoing for CSV from the site.

Example: The [NYC open data portal](https://opendata.cityofnewyork.us/) runs on Socrata. Here we'll import their infamous Central Park Squirrel Census: [https://data.cityofnewyork.us/Environment/2018-Central-Park-Squirrel-Census-Squirrel-Data/vfnx-vebw](https://data.cityofnewyork.us/Environment/2018-Central-Park-Squirrel-Census-Squirrel-Data/vfnx-vebw). Go to the API tab and grad the Endpoint for CSV (switch from JSON): 
```{r}
squirrels <- read.socrata("")
```

Enjoy all the ways that squirrels behave in Central Park.

### Clean up your environment!

Keep things tidy. If you've created variables that you don't need anymore (as we've done here), you can either 1) wipe the whole environment using the broom button, or 2) remove specific items using `rm()`

```{r}
rm(ledger, squirrels, salaries)
```

