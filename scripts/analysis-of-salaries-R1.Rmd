---
title: "Finding the story in salaries data"
author: "Liz Lucas, IRE"
output: html_document
---

Now you'll put into practice the functions you've learned so far to
interrogate some salary data from Bloomington, IN, that came from a
records request. We have cleaned up the data a little for the purposes
of this class, but left it in spreadsheet format, so shortly you'll
learn how to import data from an Excel file (either .xls or .xlsx).

First, open up Bloomington_Salaries.xlsx in Excel by double-clicking on
the file in Finder. Note that it has two tabs: one with the data, an
another with notes on the Source. This is best practice for keeping
track of when and where you received data. But you only want to import
the first tab into R for analysis.

To do that, we need a new R package called `readxl`. This was installed
in Introduction.Rmd, but in order to use the functions that are included
in the package, you'll need to *import* it into this script using the
library() function, along with `tidyverse`:

```{r}
library(tidyverse)
library(readxl)
```

There are many functions available in `readxl`, the one you'll use now
is read_excel(). This function has an optional argument called "sheet"
which allows you to specify, numerically, which sheet or sheets you want
to import. We want the first one:

```{r}
read_excel("data/Bloomington Salaries.xlsx", sheet=1)
```

**Remember!** The results of any function - including read_excel() -
either print to the console or save to a variable. If you want to refer
to this data table later and pipe it into functions, you need to save it
to a variable. Call it "salaries":

```{r}
salaries <- read_excel("data/Bloomington Salaries.xlsx", sheet=1)
```

Take a look at the salaries data: click on the word "salaries" in your
Environment (upper right). Take a minute or two to look at the data:
What is one row of data? (One employee) What columns of information do
you have?

We can use a function called `str()` to see the structure of our data
table.

```{r}
str(salaries)
```

Note that there are NAs in the overtime_oncall, hourly_rate, and
salary_2021 columns. NAs are *NULL* values, not blanks.

# Practice

Start with some basic questions:

*Your turn!* How many employees in our data? (You may already know the
answer to this, but write some code anyway!)



*Your turn!* Who made the most in total compensation? Who made the
least? (Hint: use arrange() to sort your data)



*Your turn!* Who made the most in overtime/oncall pay?



What do you see in the results? What questions does that spark for you,
a journalist? What questions might you have for the city?

What is the total payroll for the city? Reminder: when you're no longer
asking questions with regard to specific employees, your unit of
analysis has changed. If you want to look at payroll for the whole city,
you need to do some aggregating. In this case, we want to sum up payroll
for the entire data set:

```{r}
salaries %>% 
  summarise(total_payroll = sum(total_comp))
```

What is the total overtime/oncall pay?

```{r}
salaries %>% 
  summarise(total_payroll = sum(overtime_oncall))
```

Here's where NAs (NULLs) will trip you up. If you sum a column with NAs
in it, R will return an NA. So you need to exclude the NAs in your
summing. Thankfully there is an EASY way to do this; the sum() function
will take an additional argument: `na.rm=T`, which means remove NAs.
Adding it looks like this:

```{r}
salaries %>% 
  summarise(total_payroll = sum(overtime_oncall, na.rm=T))
```

That's why it's important to take note of NAs in your data! Anytime you
want to sum a column with NAs, you need to include this argument in the
aggregate function: `na.rm=T`

*Your turn!* What's the average and median salary for 2021? Hourly rate?
(Note: both of these have NAs, so code accordingly)



# Getting to know your data

There's a very useful function in tidyverse for assessing what's in a
particular column. For example, if you are familiar with SQL, this is
the equivalent of the "golden query." If you regularly use spreadsheets,
this is the equivalent of putting a column in the Rows box and
calculating the count() function on each group.

This function happens to be called count(). Try it out on the job_title
column:

```{r}
salaries %>% 
  count(job_title)
```

You see a list of all unique job titles and how many times each value
appears in the data (i.e. how many rows have that value in the job_title
column). The count() function automatically labels the values column
`n`. Re-sort the results to see which job titles are the most common:

```{r}
salaries %>% 
  count(job_title) %>% 
  arrange(desc(n))
```

*Your turn!* Try using the count() function on department. How clean are
the department names?



Let's see if any employees are in here more than once. We wouldn't
expect them to be since each row is one employee. We'll count the last
name and first name to see how often each unique combination shows up,
and then arrange our results by the descending count.

```{r}
salaries %>% 
  count(last_name, first_name) %>% 
  arrange(desc(n))
```

*Your turn!* Use the filter() to look at the rows for Emily Herr. What
can we learn about her work. Does it make sense that she's in here
twice, or is this potentially an error in the data?



# Asking questions

How many people work for the police department?

```{r}
salaries %>% 
  filter(department == "Police")
```

What's the average total compensation for a police employee?

```{r}
salaries %>% 
  filter(department == "Police") %>% 
  summarise(avg_pay = mean(total_comp))
```

*Your turn!* Calculate the average compensation for each job title
within the Police department:



How does the average police compensation compare to other departments?
Calculate the average compensation by department, using group_by():

```{r}
salaries %>% 
  group_by(department) %>% 
  summarise(avg_comp = mean(total_comp)) %>% 
  arrange(desc(avg_comp))
```

Just like a pivot table in Excel, we can add more calculations to this
to give us more context. Right now we're look at the **average
compensation** by department. Let's add two more columns: **total
compensation** by department and the **number of employees** in each
department.

```{r}
salaries %>% 
  group_by(department) %>% 
  summarise(avg_comp = mean(total_comp),
            total_comp = sum(total_comp),
            num_employees = n())
```

*Your turn!* Let's find the same calculations for the job titles. For
each job title, calculate the following:

-   Average compensation

-   Total compensation

-   Number of people with that job title

Arrange your results by the job title that has the highest average
compensation.



Let's add one more layer to this. It makes sense that there are some
jobs held by one person that pay a lot (ie. mayor, chief) so let's
filter our results to only show us [jobs held by at least 10
people]{.underline}. We can do this by filtering after we do our
calculations.

```{r}
salaries %>% 
  group_by(job_title) %>% 
  summarise(avg_comp = mean(total_comp),
            total_comp = sum(total_comp),
            num_employees = n()) %>% 
  filter(num_employees > 10)
```

Let's dig into the job titles a bit. So far we have only looked at exact
matches, but text fields can have some (or a lot of) variation in them.
For example, lots of jobs could have the word 'Director' in them.

If we wanted to find every job title with that word in it, we can use a
function called `grepl()` ***INSIDE*** our `filter()` function. This
performs a wildcard match.

```{r}
salaries %>% 
  filter(grepl("Director", job_title))
```

In this example, we can see we have 41 employees with the word
'Director' in their job title. (Remember, R is case sensitive!)

We'll store these directors to their own data frame so we can run more
queries against them.

```{r}
directors <- salaries %>% filter(grepl("Director", job_title))
```

*Your turn!* Which department pays the highest average salary to people
with director in their job title?



*Your turn!* Let's return to the original salaries data frame. Use
filter and grepl to find all the people who work in the various
Utilities departments. (If you need to refresh your memory, click on the
word "salaries" in your Environment (upper right).) Once you've
successfully run this code, store these employees to their own data
frame called **utilities**.




*Your turn!* Which job in the various Utilities department pays the
best? (This question is intentionally vague! Think about the various
calculations you can do and pick one -- or multiple -- to try to come up
with a conclusion.)



# Extra practice!

1.  What do people with the word 'Specialist' in their job title make in
    total compensation, on average?



2.  What do interns make?



3.  Which department paid out the most in overtime/on-call pay?



4.  Which department has the most employees paid hourly?



5.  For police employees, find the percent of their total compensation
    comes from overtime for each employee.

    Do this in two steps: First, create a data frame called police of
    just employees who work for the police department. If you do this
    correctly, you will see police show up in your Environment sidebar.
    Then, using this new police dataframe, you will use mutate() to add
    a column and do a percent of total calculation.


